{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TBRKMfqbIEDH"
      },
      "outputs": [],
      "source": [
        "# Verify Google gave you GPU runtime and switch using upper right dropdown above if not\n",
        "!nvidia-smi -L\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmBxfieaJM4K"
      },
      "outputs": [],
      "source": [
        "# Set up colab paths\n",
        "temp_colab_path = '/content/invokeai_temp_colab'\n",
        "persist_colab_path = '/content/drive/MyDrive/invokeai_persist_colab'\n",
        "\n",
        "# Set if instance should use temporary storage (temp_colab_path) or persistent storage (persist_colab_path)\n",
        "chosen_colab_path = temp_colab_path\n",
        "\n",
        "# Set up temporary storage if needed\n",
        "if chosen_colab_path == temp_colab_path:\n",
        "    import os\n",
        "    if not os.path.exists(temp_colab_path):\n",
        "      os.makedirs(temp_colab_path)\n",
        "\n",
        "# Mount and set up Google drive if needed/isn't already\n",
        "if chosen_colab_path == persist_colab_path:\n",
        "  import os\n",
        "  from google.colab import drive\n",
        "  if not os.path.exists(persist_colab_path):\n",
        "    drive.mount('/content/drive')\n",
        "    if not os.path.exists(persist_colab_path):\n",
        "      os.makedirs(persist_colab_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sign up/accept terms/get tokens at https://huggingface.co/runwayml/stable-diffusion-v1-5 https://huggingface.co/runwayml/stable-diffusion-inpainting https://ngrok.com/\n",
        "huggingface_token = 'HF_TOKEN_HERE'\n",
        "ngrok_token = 'NGROK_TOKEN_HERE'"
      ],
      "metadata": {
        "id": "W3EC8CKJXpSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7U8CIkP3V2f"
      },
      "outputs": [],
      "source": [
        "# Create InvokeAI root\n",
        "invokeai_root = chosen_colab_path + '/invokeai'\n",
        "import os\n",
        "os.environ['INVOKEAI_ROOT'] = invokeai_root\n",
        "if not os.path.exists(invokeai_root):\n",
        "  os.makedirs(invokeai_root)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XDrOUKU63uHj"
      },
      "outputs": [],
      "source": [
        "# Create and prepare virtual environment\n",
        "%cd {invokeai_root}\n",
        "!python -m venv .venv --prompt InvokeAI\n",
        "!deactivate && source .venv/bin/activate; python -m pip install --upgrade pip\n",
        "!source .venv/bin/activate; pip install InvokeAI[xformers] --use-pep517 --extra-index-url https://download.pytorch.org/whl/cu117"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "osE_8sgU5Mh7"
      },
      "outputs": [],
      "source": [
        "# Download and configure models\n",
        "%cd {invokeai_root}\n",
        "import os\n",
        "os.environ['HUGGING_FACE_HUB_TOKEN'] = huggingface_token\n",
        "# Comment out the final flag of the line below to automatically download the default models\n",
        "!source .venv/bin/activate; invokeai-configure --yes --skip-sd-weights\n",
        "!sed -i 's/nsfw_checker: true/nsfw_checker: false/' invokeai.yaml # performance > trauma"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import custom models\n",
        "#!invokeai-model-install --add HF_MODEL_HERE"
      ],
      "metadata": {
        "id": "AitkguYp6IWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install and run NGROK proxy\n",
        "%cd {chosen_colab_path}\n",
        "!pip install pyngrok --quiet\n",
        "from pyngrok import ngrok\n",
        "ngrok.kill()\n",
        "ngrok.set_auth_token(ngrok_token)\n",
        "public_url = ngrok.connect(9090, \"http\").public_url\n",
        "print(f'InvokeAI Public URL: {public_url}')"
      ],
      "metadata": {
        "id": "8VM4RsMkfB7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yyOhF3zSYLse"
      },
      "outputs": [],
      "source": [
        "# Start site\n",
        "%cd {invokeai_root}\n",
        "!source .venv/bin/activate; invokeai-web --host 0.0.0.0"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}